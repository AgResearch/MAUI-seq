# Copyright: CC BY-SA 4.0 - 2025 Benjamin J Perry
# Version: 1.0
# Maintainer: Benjamin J Perry
# Email: ben.perry@agresearch.co.nz
import os
import re
from snakemake.utils import min_version

min_version("9")

print(f"Working directory: {os.getcwd()}")
print("TOOLS: ")
os.system('echo "  bash: $(which bash)"')
os.system('echo "  PYTHON: $(which python)"')
os.system('echo "  CONDA: $(which conda)"')
os.system('echo "  SNAKEMAKE: $(which snakemake)"')
print(f"  TMPDIR = {os.environ.get('TMPDIR', '<n/a>')}")
os.system('echo "  PYTHON VERSION: $(python --version)"')
os.system('echo "  CONDA VERSION: $(conda --version)"')


# Load configuration variables
configfile: "config/pipeline_config.yaml"


amplicons = ["recA", "rpoB", "nodA", "nodD"]

# Expected fastq data to be generated using wgs_prism
RUN_PATH = config["RUN_PATH"]
FASTQ_PATH = os.path.join(config["RUN_PATH"], "SampleSheet", "bclconvert")
RUN = os.path.basename(RUN_PATH)
# Capture the wildcards using the built-in glob_wildcards function
print("wildcards string: ", os.path.join(FASTQ_PATH, "{samples}_R1_001.fastq.gz"))
SAMPLES = glob_wildcards(os.path.join(FASTQ_PATH, "{samples}_R1_001.fastq.gz"))


# Global minimum read count for filtering assembled reads
min_reads = 2500

# env definitions
seqkit_env = "envs/seqkit-2.4.yaml"
pear_env = "envs/pear-0.9.6.yaml"
cutadapt_env = "envs/cutadapt-4.4.yaml"


wildcard_constraints:
    samples=r"[a-zA-Z0-9\-\_]+",


rule all:
    input:
        os.path.join("results", RUN, "00_QC", "report_seqkit_raw.txt"),
        os.path.join("results", RUN, "00_QC", "report_seqkit_assembled.txt"),
        os.path.join("results", RUN, "00_QC", "report_seqkit_discarded.txt"),
        os.path.join("results", RUN, "00_QC", "report_seqkit_unassembled_forward.txt"),
        os.path.join("results", RUN, "00_QC", "report_seqkit_unassembled_reverse.txt"),
        collect(
            os.path.join("results", RUN, "03_amplicons", "{amplicons}", "{samples}.{amplicons}.fastq"),
            amplicons=amplicons,
            samples=SAMPLES.samples,
        ),
        collect(
            os.path.join("results", RUN, "04_MAUIcount", "{amplicons}", "MAUIcount_output", "summary.txt"),
            amplicons=amplicons,
        ),


rule report_seqkit_raw:
    input:
        read1=collect(
            os.path.join(FASTQ_PATH, "{samples}_R1_001.fastq.gz"),
            samples=SAMPLES.samples,
        ),
        read2=collect(
            os.path.join(FASTQ_PATH, "{samples}_R2_001.fastq.gz"),
            samples=SAMPLES.samples,
        ),
    output:
        report=os.path.join("results", RUN, "00_QC", "report_seqkit_raw.txt"),
    log:
        os.path.join("results", RUN, "logs", "report_seqkit_raw.log"),
    benchmark:
        os.path.join("results", RUN, "benchmarks", "report_seqkit_raw.txt")
    conda:
        seqkit_env
    threads: 12
    resources:
        mem_gb=lambda wildcards, attempt: 4 + ((attempt - 1) * 4),
        time=lambda wildcards, attempt: 30 + ((attempt - 1) * 60),
        partition="compute,hugemem,vgpu",
    shell:
        "seqkit "
        "stats "
        "-j {threads} "
        "-a {input.read1} {input.read2} "
        "-o {output} "
        "2>&1 | tee {log} "


rule pear_read_assemble:
    input:
        read1=os.path.join(FASTQ_PATH, "{samples}_R1_001.fastq.gz"),
        read2=os.path.join(FASTQ_PATH, "{samples}_R2_001.fastq.gz"),
    output:
        assembled=os.path.join(
            "results", RUN, "01_assembled", "{samples}.assembled.fastq"
        ),
        discarded=temp(
            os.path.join("results", RUN, "01_assembled", "{samples}.discarded.fastq")
        ),
        unassembled_forward=temp(
            os.path.join(
                "results", RUN, "01_assembled", "{samples}.unassembled.forward.fastq"
            )
        ),
        unassembled_reverse=temp(
            os.path.join(
                "results", RUN, "01_assembled", "{samples}.unassembled.reverse.fastq"
            )
        ),
    conda:
        pear_env
    log:
        os.path.join("results", RUN, "logs", "pear_read_assemble.{samples}.log"),
    benchmark:
        os.path.join("results", RUN, "benchmarks", "pear_read_assemble.{samples}.txt")
    threads: 8
    resources:
        mem_gb=8,
        time=60,
        partition="compute,hugemem",
    shell:
        "pear "
        "--threads {threads} "
        "--memory {resources.mem_gb}G "
        "--forward-fastq {input.read1} "
        "--reverse-fastq {input.read2} "
        "--output results/{RUN}/01_assembled/{wildcards.samples} "
        "2>&1 | tee {log} "


rule report_seqkit_assembled:
    input:
        reads=collect(
            os.path.join("results", RUN, "01_assembled", "{samples}.assembled.fastq"),
            samples=SAMPLES.samples,
        ),
    output:
        report=os.path.join("results", RUN, "00_QC", "report_seqkit_assembled.txt"),
    log:
        os.path.join("results", RUN, "logs", "report_seqkit_assembled.log"),
    benchmark:
        os.path.join("results", RUN, "benchmarks", "report_seqkit_assembled.txt")
    conda:
        seqkit_env
    threads: 12
    resources:
        mem_gb=lambda wildcards, attempt: 4 + ((attempt - 1) * 4),
        time=lambda wildcards, attempt: 30 + ((attempt - 1) * 60),
        partition="compute,hugemem,vgpu",
    shell:
        "seqkit "
        "stats "
        "-j {threads} "
        "-a {input.reads} "
        "-o {output.report} "
        "2>&1 | tee {log} "


rule report_seqkit_discarded:
    input:
        reads=collect(
            os.path.join("results", RUN, "01_assembled", "{samples}.discarded.fastq"),
            samples=SAMPLES.samples,
        ),
    output:
        report=os.path.join("results", RUN, "00_QC", "report_seqkit_discarded.txt"),
    log:
        os.path.join("results", RUN, "logs", "report_seqkit_discarded.log"),
    benchmark:
        os.path.join("results", RUN, "benchmarks", "report_seqkit_discarded.txt")
    conda:
        seqkit_env
    threads: 12
    resources:
        mem_gb=lambda wildcards, attempt: 4 + ((attempt - 1) * 4),
        time=lambda wildcards, attempt: 30 + ((attempt - 1) * 60),
        partition="compute,hugemem,vgpu",
    shell:
        "seqkit "
        "stats "
        "-j {threads} "
        "-a {input.reads} "
        "-o {output.report} "
        "2>&1 | tee {log} "


rule report_seqkit_unassembled_forward:
    input:
        reads=collect(
            os.path.join(
                "results", RUN, "01_assembled", "{samples}.unassembled.forward.fastq"
            ),
            samples=SAMPLES.samples,
        ),
    output:
        report=os.path.join(
            "results", RUN, "00_QC", "report_seqkit_unassembled_forward.txt"
        ),
    log:
        os.path.join("results", RUN, "logs", "report_seqkit_unassembled_forward.log"),
    benchmark:
        os.path.join(
            "results", RUN, "benchmarks", "report_seqkit_unassembled_forward.txt"
        )
    conda:
        seqkit_env
    threads: 12
    resources:
        mem_gb=lambda wildcards, attempt: 4 + ((attempt - 1) * 4),
        time=lambda wildcards, attempt: 30 + ((attempt - 1) * 60),
        partition="compute,hugemem,vgpu",
    shell:
        "seqkit "
        "stats "
        "-j {threads} "
        "-a {input.reads} "
        "-o {output.report} "
        "2>&1 | tee {log} "


rule report_seqkit_unassembled_reverse:
    input:
        reads=collect(
            os.path.join(
                "results", RUN, "01_assembled", "{samples}.unassembled.reverse.fastq"
            ),
            samples=SAMPLES.samples,
        ),
    output:
        report=os.path.join(
            "results", RUN, "00_QC", "report_seqkit_unassembled_reverse.txt"
        ),
    log:
        os.path.join("results", RUN, "logs", "report_seqkit_unassembled_reverse.log"),
    benchmark:
        os.path.join(
            "results", RUN, "benchmarks", "report_seqkit_unassembled_reverse.txt"
        )
    conda:
        seqkit_env
    threads: 12
    resources:
        mem_gb=lambda wildcards, attempt: 4 + ((attempt - 1) * 4),
        time=lambda wildcards, attempt: 30 + ((attempt - 1) * 60),
        partition="compute,hugemem,vgpu",
    shell:
        "seqkit "
        "stats "
        "-j {threads} "
        "-a {input.reads} "
        "-o {output.report} "
        "2>&1 | tee {log} "


# def get_seqkit_passing_samples(wildcards, minReads=min_reads, library=LIBRARY):
#     file = checkpoints.report_seqkit_raw.get().output[0]
#     qc_stats = pd.read_csv(file, delimiter = r"\s+")
#     qc_stats["num_seqs"] = qc_stats["num_seqs"].str.replace(",", "").astype(int)
#     qc_passed = qc_stats.loc[qc_stats["num_seqs"].astype(int) > minReads]
#     passed = qc_passed['file'].str.split("/").str[-1].str.split(".").str[0].tolist()
#     return collect(os.path.join("results", library, "02_kneaddata/{samples}.fastq.gz"), samples = passed)
#


checkpoint cutadapt_amplicon_demux:
    input:
        assembled=os.path.join(
            "results", RUN, "01_assembled", "{samples}.assembled.fastq"
        ),
    output:
        demuxed_dir=directory(os.path.join("results", RUN, "02_cutadapt", "{samples}")),
    log:
        os.path.join("results", RUN, "logs", "cutadapt_amplicon_demux.{samples}.log"),
    benchmark:
        os.path.join(
            "results", RUN, "benchmarks", "cutadapt_amplicon_demux.{samples}.txt"
        )
    conda:
        cutadapt_env
    threads: 8
    resources:
        mem_gb=8,
        time=60,
        partition="compute,hugemem,vgpu",
    params:
        barcodes="resources/amplicon_barcodes.fasta",
    shell:
        "mkdir -p {output.demuxed_dir} && "
        "cat {input.assembled} | "
        "cutadapt "
        "-j {threads} "
        "--discard-untrimmed "
        "--no-indels "
        "-e 0 "
        "--action=none "
        "-g file:{params.barcodes} "
        r'-o "{output.demuxed_dir}/{wildcards.samples}.{{name}}.fastq.gz" '
        "-"


def get_amplicon_files(wildcards):
    import glob

    checkpoint_output = checkpoints.cutadapt_amplicon_demux.get(
        samples=wildcards.samples
    ).output[0]
    # Get all .fastq.gz files in the directory
    files = glob.glob(
        os.path.join(checkpoint_output, f"{wildcards.samples}.*.fastq.gz")
    )
    # Filter for the specific amplicon
    target_file = os.path.join(
        checkpoint_output, f"{wildcards.samples}.{wildcards.amplicons}.fastq.gz"
    )
    return target_file


rule gather_gene_amplicons:
    input:
        demuxed_file=get_amplicon_files,
    output:
        gene_amplicon=os.path.join(
            "results",
            RUN,
            "03_amplicons",
            "{amplicons}",
            "{samples}.{amplicons}.fastq",
        ),
    resources:
        mem_gb=2,
        time=10,
        partition="compute,hugemem,vgpu",
    shell:
        """
        gunzip -c {input.demuxed_file} > {output.gene_amplicon}
    
        """


rule run_MAUIcount:
    input:
        amplicon_files=lambda wildcards: collect(
            os.path.join("results", RUN, "03_amplicons", wildcards.amplicons, ("{samples}." + wildcards.amplicons + ".fastq")),
            samples=SAMPLES.samples,
        ),
    output:
        results_dir=directory(
            os.path.join("results", RUN, "04_MAUIcount", "{amplicons}")
        ),
        summary=os.path.join(
            "results",
            RUN,
            "04_MAUIcount",
            "{amplicons}",
            "MAUIcount_output",
            "summary.txt",
        ),
    params:
        amplicon_dir=lambda wildcards: os.path.join(
            "results", RUN, "03_amplicons", wildcards.amplicons
        ),
        amplicon_config="resources/amplicon_config.yaml",
    log:
        os.path.join("results", RUN, "04_MAUIcount", "{amplicons}", "MAUIcount.{amplicons}.log"),
    benchmark:
        os.path.join("results", RUN, "benchmarks", "MAUIcount.{amplicons}.txt")
    conda:
        "envs/mauiseq.yaml"
    threads: 1
    resources:
        mem_gb=8,
        time=120,
        partition="compute,hugemem,vgpu",
    shell:
        """
        
        # Create symbolic links in the MAUIcount results directory
        for FILE in {input.amplicon_files}; do
            ln -s $(pwd)/$FILE $(pwd)/{output.results_dir}/$(basename $FILE)
        done
        
        echo "Links created in {output.results_dir}:"
        ls -lh {output.results_dir}

        echo "Running MAUIcount for {wildcards.amplicons}."

        # Run MAUIcount
        workflow/scripts/MAUIcount.py \
            --working-folder {output.results_dir} \
            --amplicon-config {params.amplicon_config} \
            --gene {wildcards.amplicons} \
            --output-read-counts \
            2>&1 | tee {log}
        """
